2025-12-17 23:48:40,644 - __main__ - INFO - ====================================================================================================
2025-12-17 23:48:40,644 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 23:48:40,644 - __main__ - INFO - ====================================================================================================
2025-12-17 23:48:40,644 - __main__ - INFO - Experiment: geneformer_perturbation_100_genes
2025-12-17 23:48:40,649 - __main__ - INFO - 
Configuration:
seed: 42
model:
  name: gf-12L-38M-i4096
  batch_size: 128
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
perturbation:
  gene_list: null
  num_genes: 100
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - all
  batching:
    enabled: true
    batch_size_multiplier: 2
  quantization:
    enabled: true
    dtype: float16
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: true
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
experiment:
  name: geneformer_perturbation_100_genes
  tags: []
  notes: ''
reproducibility:
  deterministic: true
advanced:
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 23:48:40,649 - __main__ - INFO - Loading Geneformer model...
2025-12-17 23:48:44,054 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 23:48:44,054 - __main__ - INFO - Loading data: norman_2019
2025-12-17 23:49:08,997 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 23:49:08,997 - __main__ - INFO - Preprocessing data...
2025-12-17 23:49:11,353 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 23:49:11,513 - __main__ - INFO - Data normalized
2025-12-17 23:49:11,514 - __main__ - INFO - Tokenizing data...
2025-12-17 23:49:17,994 - __main__ - INFO - Tokenization complete
2025-12-17 23:49:18,181 - __main__ - INFO - Selected 100 genes using method: top_expressed
2025-12-17 23:49:18,181 - __main__ - INFO - 
====================================================================================================
2025-12-17 23:49:18,181 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 23:49:18,184 - __main__ - INFO - Extracting embeddings...
2025-12-17 23:49:18,553 - __main__ - ERROR - Baseline failed: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 14.58 GiB of which 4.59 GiB is free. Process 36494 has 9.98 GiB memory in use. Of the allocated memory 9.15 GiB is allocated by PyTorch, and 16.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1074, in run
    perf_metrics, outputs = self.run_baseline(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 554, in run_baseline
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 493, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 193, in get_embs
    outputs = model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1110, in forward
    extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 451, in _prepare_4d_attention_mask_for_sdpa
    return AttentionMaskConverter._expand_mask(mask=mask, dtype=dtype, tgt_len=tgt_len)
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 190, in _expand_mask
    inverted_mask = 1.0 - expanded_mask
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 45, in wrapped
    return f(self, *args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 1075, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 14.58 GiB of which 4.59 GiB is free. Process 36494 has 9.98 GiB memory in use. Of the allocated memory 9.15 GiB is allocated by PyTorch, and 16.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-17 23:49:18,565 - __main__ - INFO - 
====================================================================================================
2025-12-17 23:49:18,565 - __main__ - INFO - Running with BATCHING optimization...
2025-12-17 23:49:18,565 - __main__ - INFO - Using batch size: 256 (original: 128)
2025-12-17 23:49:18,567 - __main__ - INFO - Extracting embeddings...
2025-12-17 23:49:19,066 - __main__ - ERROR - batching failed: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 14.58 GiB of which 11.59 GiB is free. Process 36494 has 2.98 GiB memory in use. Of the allocated memory 2.16 GiB is allocated by PyTorch, and 8.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1124, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 617, in run_with_batching
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 493, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 193, in get_embs
    outputs = model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1110, in forward
    extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 451, in _prepare_4d_attention_mask_for_sdpa
    return AttentionMaskConverter._expand_mask(mask=mask, dtype=dtype, tgt_len=tgt_len)
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 188, in _expand_mask
    expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 14.58 GiB of which 11.59 GiB is free. Process 36494 has 2.98 GiB memory in use. Of the allocated memory 2.16 GiB is allocated by PyTorch, and 8.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-17 23:49:19,067 - __main__ - INFO - 
====================================================================================================
2025-12-17 23:49:19,067 - __main__ - INFO - Running with QUANTIZATION optimization...
2025-12-17 23:49:19,067 - __main__ - INFO - Applying float16 precision...
2025-12-17 23:49:19,073 - __main__ - INFO - Extracting embeddings...
2025-12-17 23:49:19,510 - __main__ - ERROR - quantization failed: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 14.58 GiB of which 11.67 GiB is free. Process 36494 has 2.90 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 1.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1124, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 703, in run_with_quantization
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 493, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 193, in get_embs
    outputs = model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1110, in forward
    extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 451, in _prepare_4d_attention_mask_for_sdpa
    return AttentionMaskConverter._expand_mask(mask=mask, dtype=dtype, tgt_len=tgt_len)
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 188, in _expand_mask
    expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 14.58 GiB of which 11.67 GiB is free. Process 36494 has 2.90 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 1.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-17 23:49:19,510 - __main__ - INFO - 
====================================================================================================
2025-12-17 23:49:19,510 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 23:49:19,510 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 23:49:19,512 - __main__ - INFO - Extracting embeddings...
2025-12-17 23:49:19,512 - __main__ - ERROR - distributed failed: 'DataParallel' object has no attribute 'bert'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1124, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 851, in run_with_distributed
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 493, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 160, in get_embs
    model_input_size = get_model_input_size(model)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 262, in get_model_input_size
    return int(re.split("\(|,", str(model.bert.embeddings.position_embeddings))[1])
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1964, in __getattr__
    raise AttributeError(
AttributeError: 'DataParallel' object has no attribute 'bert'
2025-12-17 23:49:19,512 - __main__ - INFO - 
====================================================================================================
2025-12-17 23:49:19,513 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 23:49:19,513 - __main__ - INFO - ====================================================================================================
2025-12-17 23:49:19,513 - __main__ - ERROR - No methods completed successfully
