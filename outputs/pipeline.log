2025-12-17 21:06:37,668 - __main__ - INFO - ====================================================================================================
2025-12-17 21:06:37,668 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:06:37,668 - __main__ - INFO - ====================================================================================================
2025-12-17 21:06:37,668 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:06:37,673 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:06:37,673 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:06:48,289 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:06:48,290 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:07:59,603 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:07:59,603 - __main__ - INFO - Preprocessing data...
2025-12-17 21:08:02,113 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:08:05,440 - __main__ - INFO - Data normalized
2025-12-17 21:08:05,446 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:08:05,448 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:08:05,448 - __main__ - INFO - Tokenizing data...
2025-12-17 21:08:06,617 - __main__ - INFO - Tokenization complete
2025-12-17 21:08:06,617 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:08:06,617 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:08:06,617 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:08:06,620 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:08,401 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:08,401 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:08:08,401 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:08:08,401 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:08:08,940 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:09,637 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:09,637 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:08:09,637 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:08:10,154 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:10,724 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:10,724 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:08:10,724 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:08:11,240 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:11,798 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:11,798 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:08:11,798 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:08:12,321 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:12,885 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:12,886 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:08:12,886 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:08:13,398 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:13,960 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:13,961 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:08:13,961 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:08:14,476 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:15,037 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:15,037 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:08:15,037 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:08:15,552 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:16,112 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:16,112 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:08:16,112 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:08:16,623 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:17,187 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:17,187 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:08:17,187 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:08:17,716 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:18,280 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:18,280 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:08:18,280 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:08:18,774 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:19,334 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:08:19,334 - __main__ - INFO - Perturbation complete
2025-12-17 21:08:19,358 - __main__ - INFO - Saved outputs for baseline to outputs/outputs/baseline
2025-12-17 21:08:19,367 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:08:19,367 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:08:19,367 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 21:08:19,369 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:08:19,369 - __main__ - ERROR - distributed failed: 'DataParallel' object has no attribute 'get_embeddings'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1120, in run
    try:
  File "/root/capsule/code/helical-challenge/main.py", line 847, in run_with_distributed
  File "/root/capsule/code/helical-challenge/main.py", line 494, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1940, in __getattr__
    raise AttributeError(
AttributeError: 'DataParallel' object has no attribute 'get_embeddings'
2025-12-17 21:08:19,373 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:08:19,374 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:08:19,374 - __main__ - INFO - ====================================================================================================
2025-12-17 21:08:19,375 - __main__ - INFO - Performance metrics saved to: outputs/performance_metrics_20251217_210819.csv
2025-12-17 21:08:19,377 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:08:19,377 - __main__ - INFO - PERFORMANCE SUMMARY
2025-12-17 21:08:19,377 - __main__ - INFO - ====================================================================================================
2025-12-17 21:08:19,380 - __main__ - INFO - 
     method  runtime_seconds  cpu_percent    memory_mb  gpu_memory_mb  gpu_utilization  throughput_cells_per_sec  num_cells  num_genes_perturbed                   timestamp extra_optimization
0  baseline        12.716794         79.6  6004.730469     153.536621               40                 78.636169       1000                   10  2025-12-17T21:08:19.336199               none

2025-12-17 21:08:19,380 - __main__ - INFO - 
SPEEDUP RELATIVE TO BASELINE:
2025-12-17 21:08:19,380 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:08:19,381 - __main__ - INFO - ====================================================================================================
2025-12-17 21:08:19,381 - __main__ - INFO - 
All outputs saved to: outputs
2025-12-17 21:08:19,381 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:08:19,381 - __main__ - INFO - PIPELINE COMPLETE!
2025-12-17 21:08:19,381 - __main__ - INFO - ====================================================================================================
2025-12-17 21:10:54,893 - __main__ - INFO - ====================================================================================================
2025-12-17 21:10:54,893 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:10:54,893 - __main__ - INFO - ====================================================================================================
2025-12-17 21:10:54,893 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:10:54,898 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:10:54,899 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:11:00,227 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:11:00,227 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:11:27,410 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:11:27,410 - __main__ - INFO - Preprocessing data...
2025-12-17 21:11:29,941 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:11:30,103 - __main__ - INFO - Data normalized
2025-12-17 21:11:30,108 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:11:30,110 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:11:30,110 - __main__ - INFO - Tokenizing data...
2025-12-17 21:11:30,633 - __main__ - INFO - Tokenization complete
2025-12-17 21:11:30,634 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:11:30,634 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:11:30,634 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:11:30,637 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:32,265 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:32,266 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:11:32,266 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:11:32,266 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:11:32,780 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:33,336 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:33,336 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:11:33,336 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:11:33,854 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:34,415 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:34,415 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:11:34,415 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:11:34,933 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:35,493 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:35,493 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:11:35,493 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:11:36,013 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:36,580 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:36,580 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:11:36,580 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:11:37,098 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:37,648 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:37,648 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:11:37,648 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:11:38,170 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:38,719 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:38,719 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:11:38,719 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:11:39,237 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:39,794 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:39,794 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:11:39,794 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:11:40,316 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:40,866 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:40,866 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:11:40,866 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:11:41,382 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:41,932 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:41,932 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:11:41,932 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:11:42,446 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:43,008 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:11:43,009 - __main__ - INFO - Perturbation complete
2025-12-17 21:11:43,038 - __main__ - INFO - Saved outputs for baseline to outputs/outputs/baseline
2025-12-17 21:11:43,047 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:11:43,047 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:11:43,047 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 21:11:43,049 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:11:43,049 - __main__ - ERROR - distributed failed: 'DataParallel' object has no attribute 'bert'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1125, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 852, in run_with_distributed
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 499, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 160, in get_embs
    model_input_size = get_model_input_size(model)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 262, in get_model_input_size
    return int(re.split("\(|,", str(model.bert.embeddings.position_embeddings))[1])
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1940, in __getattr__
    raise AttributeError(
AttributeError: 'DataParallel' object has no attribute 'bert'
2025-12-17 21:11:43,051 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:11:43,051 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:11:43,051 - __main__ - INFO - ====================================================================================================
2025-12-17 21:11:43,052 - __main__ - INFO - Performance metrics saved to: outputs/performance_metrics_20251217_211143.csv
2025-12-17 21:11:43,054 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:11:43,054 - __main__ - INFO - PERFORMANCE SUMMARY
2025-12-17 21:11:43,054 - __main__ - INFO - ====================================================================================================
2025-12-17 21:11:43,057 - __main__ - INFO - 
     method  runtime_seconds  cpu_percent    memory_mb  gpu_memory_mb  gpu_utilization  throughput_cells_per_sec  num_cells  num_genes_perturbed                   timestamp extra_optimization
0  baseline        12.374516         79.0  6641.058594     153.536621               44                 80.811243       1000                   10  2025-12-17T21:11:43.010538               none

2025-12-17 21:11:43,058 - __main__ - INFO - 
SPEEDUP RELATIVE TO BASELINE:
2025-12-17 21:11:43,058 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:11:43,058 - __main__ - INFO - ====================================================================================================
2025-12-17 21:11:43,058 - __main__ - INFO - 
All outputs saved to: outputs
2025-12-17 21:11:43,058 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:11:43,058 - __main__ - INFO - PIPELINE COMPLETE!
2025-12-17 21:11:43,058 - __main__ - INFO - ====================================================================================================
2025-12-17 21:22:38,962 - __main__ - INFO - ====================================================================================================
2025-12-17 21:22:38,962 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:22:38,962 - __main__ - INFO - ====================================================================================================
2025-12-17 21:22:38,963 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:22:38,968 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: false
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:22:38,968 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:22:44,262 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:22:44,262 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:23:10,980 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:23:10,980 - __main__ - INFO - Preprocessing data...
2025-12-17 21:23:13,504 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:23:13,665 - __main__ - INFO - Data normalized
2025-12-17 21:23:13,670 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:23:13,672 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:23:13,672 - __main__ - INFO - Tokenizing data...
2025-12-17 21:23:14,198 - __main__ - INFO - Tokenization complete
2025-12-17 21:23:14,199 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:23:14,199 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:23:14,199 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:23:14,202 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:23:14,202 - __main__ - ERROR - Baseline failed: 'Dataset' object has no attribute 'get_embeddings'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1085, in run
    perf_metrics, outputs = self.run_baseline(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 566, in run_baseline
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 505, in extract_embeddings
    embeddings = model.get_embeddings(data)
AttributeError: 'Dataset' object has no attribute 'get_embeddings'
2025-12-17 21:23:14,207 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:23:14,207 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:23:14,207 - __main__ - WARNING - Only 1 GPU available, distributed mode may not provide benefits
2025-12-17 21:23:14,208 - __main__ - ERROR - distributed failed: name 'world_size' is not defined
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1135, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 861, in run_with_distributed
    nprocs=world_size, join=True)
NameError: name 'world_size' is not defined
2025-12-17 21:23:14,211 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:23:14,211 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:23:14,211 - __main__ - INFO - ====================================================================================================
2025-12-17 21:23:14,211 - __main__ - ERROR - No methods completed successfully
2025-12-17 21:27:17,101 - __main__ - INFO - ====================================================================================================
2025-12-17 21:27:17,101 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:27:17,102 - __main__ - INFO - ====================================================================================================
2025-12-17 21:27:17,102 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:27:17,107 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: false
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:27:17,107 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:27:22,517 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:27:22,517 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:27:49,200 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:27:49,200 - __main__ - INFO - Preprocessing data...
2025-12-17 21:27:51,728 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:27:51,887 - __main__ - INFO - Data normalized
2025-12-17 21:27:51,892 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:27:51,894 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:27:51,894 - __main__ - INFO - Tokenizing data...
2025-12-17 21:27:52,410 - __main__ - INFO - Tokenization complete
2025-12-17 21:27:52,411 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:27:52,411 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:27:52,411 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:27:52,414 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:27:52,414 - __main__ - ERROR - Baseline failed: 'Dataset' object has no attribute 'get_embeddings'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1088, in run
    perf_metrics, outputs = self.run_baseline(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 566, in run_baseline
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 505, in extract_embeddings
    embeddings = model.get_embeddings(data)
AttributeError: 'Dataset' object has no attribute 'get_embeddings'
2025-12-17 21:27:52,418 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:27:52,419 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:27:52,419 - __main__ - WARNING - Only 1 GPU available, distributed mode may not provide benefits
2025-12-17 21:27:52,422 - __main__ - ERROR - distributed failed: cannot pickle '_thread.RLock' object
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1138, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 859, in run_with_distributed
    mp.spawn(
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 340, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 280, in start_processes
    idx, process, tf_name = start_process(i)
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 275, in start_process
    process.start()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/opt/conda/lib/python3.10/multiprocessing/context.py", line 288, in _Popen
    return Popen(process_obj)
  File "/opt/conda/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/opt/conda/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 47, in _launch
    reduction.dump(process_obj, fp)
  File "/opt/conda/lib/python3.10/multiprocessing/reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
TypeError: cannot pickle '_thread.RLock' object
2025-12-17 21:27:52,423 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:27:52,423 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:27:52,423 - __main__ - INFO - ====================================================================================================
2025-12-17 21:27:52,423 - __main__ - ERROR - No methods completed successfully
2025-12-17 21:30:15,158 - __main__ - INFO - ====================================================================================================
2025-12-17 21:30:15,158 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:30:15,158 - __main__ - INFO - ====================================================================================================
2025-12-17 21:30:15,158 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:30:15,164 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:30:15,164 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:30:20,441 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:30:20,442 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:30:47,101 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:30:47,101 - __main__ - INFO - Preprocessing data...
2025-12-17 21:30:49,628 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:30:49,790 - __main__ - INFO - Data normalized
2025-12-17 21:30:49,795 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:30:49,797 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:30:49,798 - __main__ - INFO - Tokenizing data...
2025-12-17 21:30:50,316 - __main__ - INFO - Tokenization complete
2025-12-17 21:30:50,317 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:30:50,317 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:30:50,317 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:30:50,319 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:30:50,320 - __main__ - ERROR - Baseline failed: 'Dataset' object has no attribute 'get_embeddings'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1088, in run
    perf_metrics, outputs = self.run_baseline(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 566, in run_baseline
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 505, in extract_embeddings
    embeddings = model.get_embeddings(data)
AttributeError: 'Dataset' object has no attribute 'get_embeddings'
2025-12-17 21:30:50,324 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:30:50,324 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:30:50,324 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 21:30:50,328 - __main__ - ERROR - distributed failed: cannot pickle '_thread.RLock' object
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1138, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 859, in run_with_distributed
    mp.spawn(
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 340, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 280, in start_processes
    idx, process, tf_name = start_process(i)
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 275, in start_process
    process.start()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/opt/conda/lib/python3.10/multiprocessing/context.py", line 288, in _Popen
    return Popen(process_obj)
  File "/opt/conda/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/opt/conda/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 47, in _launch
    reduction.dump(process_obj, fp)
  File "/opt/conda/lib/python3.10/multiprocessing/reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
TypeError: cannot pickle '_thread.RLock' object
2025-12-17 21:30:50,328 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:30:50,328 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:30:50,329 - __main__ - INFO - ====================================================================================================
2025-12-17 21:30:50,329 - __main__ - ERROR - No methods completed successfully
2025-12-17 21:32:12,743 - __main__ - INFO - ====================================================================================================
2025-12-17 21:32:12,743 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:32:12,743 - __main__ - INFO - ====================================================================================================
2025-12-17 21:32:12,743 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:32:12,748 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:32:12,748 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:32:17,987 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:32:17,987 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:32:44,629 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:32:44,629 - __main__ - INFO - Preprocessing data...
2025-12-17 21:32:47,155 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:32:47,313 - __main__ - INFO - Data normalized
2025-12-17 21:32:47,318 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:32:47,321 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:32:47,321 - __main__ - INFO - Tokenizing data...
2025-12-17 21:32:47,842 - __main__ - INFO - Tokenization complete
2025-12-17 21:32:47,843 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:32:47,843 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:32:47,843 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:32:47,846 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:49,477 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:49,477 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:32:49,477 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:32:49,478 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:32:49,995 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:50,566 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:50,567 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:32:50,567 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:32:51,082 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:51,653 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:51,653 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:32:51,653 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:32:52,169 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:52,733 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:52,733 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:32:52,733 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:32:53,251 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:53,830 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:53,830 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:32:53,830 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:32:54,355 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:54,921 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:54,921 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:32:54,921 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:32:55,447 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:56,020 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:56,020 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:32:56,020 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:32:56,554 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:57,252 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:57,252 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:32:57,252 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:32:57,765 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:58,349 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:58,349 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:32:58,349 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:32:58,866 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:32:59,434 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:32:59,434 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:32:59,434 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:32:59,949 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:33:00,508 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:33:00,508 - __main__ - INFO - Perturbation complete
2025-12-17 21:33:00,537 - __main__ - INFO - Saved outputs for baseline to outputs/outputs/baseline
2025-12-17 21:33:00,547 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:33:00,547 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:33:00,547 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 21:33:00,548 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:33:00,549 - __main__ - ERROR - distributed failed: 'DataParallel' object has no attribute 'bert'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1125, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 852, in run_with_distributed
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 499, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 160, in get_embs
    model_input_size = get_model_input_size(model)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 262, in get_model_input_size
    return int(re.split("\(|,", str(model.bert.embeddings.position_embeddings))[1])
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1940, in __getattr__
    raise AttributeError(
AttributeError: 'DataParallel' object has no attribute 'bert'
2025-12-17 21:33:00,550 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:33:00,550 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:33:00,550 - __main__ - INFO - ====================================================================================================
2025-12-17 21:33:00,552 - __main__ - INFO - Performance metrics saved to: outputs/performance_metrics_20251217_213300.csv
2025-12-17 21:33:00,553 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:33:00,553 - __main__ - INFO - PERFORMANCE SUMMARY
2025-12-17 21:33:00,553 - __main__ - INFO - ====================================================================================================
2025-12-17 21:33:00,556 - __main__ - INFO - 
     method  runtime_seconds  cpu_percent    memory_mb  gpu_memory_mb  gpu_utilization  throughput_cells_per_sec  num_cells  num_genes_perturbed                   timestamp extra_optimization
0  baseline        12.664914         79.6  6637.476562     153.536621               39                 78.958293       1000                   10  2025-12-17T21:33:00.509900               none

2025-12-17 21:33:00,557 - __main__ - INFO - 
SPEEDUP RELATIVE TO BASELINE:
2025-12-17 21:33:00,557 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:33:00,557 - __main__ - INFO - ====================================================================================================
2025-12-17 21:33:00,557 - __main__ - INFO - 
All outputs saved to: outputs
2025-12-17 21:33:00,557 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:33:00,557 - __main__ - INFO - PIPELINE COMPLETE!
2025-12-17 21:33:00,557 - __main__ - INFO - ====================================================================================================
2025-12-17 21:37:40,836 - __main__ - INFO - ====================================================================================================
2025-12-17 21:37:40,836 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:37:40,836 - __main__ - INFO - ====================================================================================================
2025-12-17 21:37:40,836 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:37:40,841 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  batching:
    enabled: true
    batch_size_multiplier: 2
    use_dataloader: true
    num_workers: 4
    pin_memory: true
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: false
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:37:40,841 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:37:42,641 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:37:42,642 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:38:07,519 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:38:07,520 - __main__ - INFO - Preprocessing data...
2025-12-17 21:38:09,867 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:38:10,028 - __main__ - INFO - Data normalized
2025-12-17 21:38:10,033 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:38:10,035 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:38:10,035 - __main__ - INFO - Tokenizing data...
2025-12-17 21:38:10,935 - __main__ - INFO - Tokenization complete
2025-12-17 21:38:10,936 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:38:10,936 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:38:10,936 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:38:10,939 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:12,214 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:12,214 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:38:12,214 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:38:12,214 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:38:12,717 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:13,283 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:13,284 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:38:13,284 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:38:13,790 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:14,359 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:14,359 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:38:14,359 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:38:14,862 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:15,449 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:15,449 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:38:15,449 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:38:15,955 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:16,522 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:16,523 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:38:16,523 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:38:17,023 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:17,587 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:17,587 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:38:17,587 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:38:18,091 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:18,652 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:18,652 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:38:18,652 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:38:19,161 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:19,727 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:19,727 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:38:19,727 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:38:20,228 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:20,786 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:20,786 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:38:20,786 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:38:21,290 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:21,865 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:21,865 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:38:21,865 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:38:22,365 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:22,922 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:22,922 - __main__ - INFO - Perturbation complete
2025-12-17 21:38:22,950 - __main__ - INFO - Saved outputs for baseline to outputs/outputs/baseline
2025-12-17 21:38:22,960 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:38:22,960 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:38:22,960 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 21:38:22,961 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:26,842 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:26,842 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:38:26,842 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:38:26,842 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:38:27,359 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:29,749 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:29,749 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:38:29,749 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:38:30,259 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:32,648 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:32,648 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:38:32,648 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:38:33,155 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:35,571 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:35,571 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:38:35,571 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:38:36,080 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:38,872 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:38,872 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:38:38,872 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:38:39,394 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:41,785 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:41,785 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:38:41,785 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:38:42,299 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:44,696 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:44,696 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:38:44,696 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:38:45,198 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:47,590 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:47,590 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:38:47,590 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:38:48,094 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:50,503 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:50,503 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:38:50,503 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:38:51,006 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:53,786 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:53,786 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:38:53,786 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:38:54,295 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:38:56,710 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:38:56,710 - __main__ - INFO - Perturbation complete
2025-12-17 21:38:56,762 - __main__ - INFO - Saved outputs for distributed to outputs/outputs/distributed
2025-12-17 21:38:56,849 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:38:56,849 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:38:56,849 - __main__ - INFO - ====================================================================================================
2025-12-17 21:38:56,849 - __main__ - INFO - Comparing baseline vs distributed
2025-12-17 21:38:57,003 - __main__ - INFO - Performance metrics saved to: outputs/performance_metrics_20251217_213857.csv
2025-12-17 21:38:57,004 - __main__ - INFO - Comparison metrics saved to: outputs/comparison_metrics_20251217_213857.csv
2025-12-17 21:38:57,005 - __main__ - INFO - Per-gene comparison saved to: outputs/gene_comparison_baseline_vs_distributed.csv
2025-12-17 21:38:57,005 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:38:57,005 - __main__ - INFO - PERFORMANCE SUMMARY
2025-12-17 21:38:57,005 - __main__ - INFO - ====================================================================================================
2025-12-17 21:38:57,009 - __main__ - INFO - 
        method  runtime_seconds  cpu_percent    memory_mb  gpu_memory_mb  gpu_utilization  throughput_cells_per_sec  num_cells  num_genes_perturbed                   timestamp extra_optimization  extra_num_gpus extra_backend
0     baseline        11.985630         78.5  2180.886719     153.536621               39                 83.433243       1000                   10  2025-12-17T21:38:22.923880               none             NaN           NaN
1  distributed        33.750403        156.2  3099.000000     162.161621               48                 29.629275       1000                   10  2025-12-17T21:38:56.740191                NaN             4.0          nccl

2025-12-17 21:38:57,009 - __main__ - INFO - 
SPEEDUP RELATIVE TO BASELINE:
2025-12-17 21:38:57,009 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:38:57,010 - __main__ - INFO - distributed         : 0.36x
2025-12-17 21:38:57,010 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:38:57,010 - __main__ - INFO - OUTPUT COMPARISON SUMMARY
2025-12-17 21:38:57,010 - __main__ - INFO - ====================================================================================================
2025-12-17 21:38:57,012 - __main__ - INFO - 
   method_a     method_b  embedding_pearson  embedding_spearman  embedding_cosine_similarity  embedding_mse  embedding_max_abs_diff  mean_perturbation_correlation  min_perturbation_correlation  max_perturbation_correlation                   timestamp
0  baseline  distributed           0.999998            0.999998                     0.999999   7.678967e-07                0.043351                       0.999997                      0.999993                      0.999999  2025-12-17T21:38:57.001160

2025-12-17 21:38:57,012 - __main__ - INFO - 
OUTPUT QUALITY ASSESSMENT:
2025-12-17 21:38:57,012 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:38:57,013 - __main__ - INFO - ====================================================================================================
2025-12-17 21:38:57,013 - __main__ - INFO - 
All outputs saved to: outputs
2025-12-17 21:38:57,013 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:38:57,013 - __main__ - INFO - PIPELINE COMPLETE!
2025-12-17 21:38:57,013 - __main__ - INFO - ====================================================================================================
2025-12-17 21:55:14,437 - __main__ - INFO - ====================================================================================================
2025-12-17 21:55:14,437 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 21:55:14,437 - __main__ - INFO - ====================================================================================================
2025-12-17 21:55:14,438 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 21:55:14,443 - __main__ - INFO - 
Configuration:
seed: 42
verbose: true
model:
  name: gf-12L-38M-i4096
  batch_size: 32
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  - batching
  - quantization
  batching:
    enabled: true
    batch_size_multiplier: 2
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: null
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: true
  cudnn_benchmark: true
  empty_cache_between_methods: true
  max_memory_gb: null
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
  benchmark: false
advanced:
  gradient_checkpointing: false
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
  max_retries: 3
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 21:55:14,443 - __main__ - INFO - Loading Geneformer model...
2025-12-17 21:55:16,530 - __main__ - INFO - Enabling automatic mixed precision
2025-12-17 21:55:16,530 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 21:55:16,530 - __main__ - INFO - Loading data: norman_2019
2025-12-17 21:55:41,784 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 21:55:41,784 - __main__ - INFO - Preprocessing data...
2025-12-17 21:55:44,157 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 21:55:44,338 - __main__ - INFO - Data normalized
2025-12-17 21:55:44,343 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 21:55:44,345 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 21:55:44,345 - __main__ - INFO - Tokenizing data...
2025-12-17 21:55:45,277 - __main__ - INFO - Tokenization complete
2025-12-17 21:55:45,278 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 21:55:45,278 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:55:45,278 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 21:55:45,347 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:47,139 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:47,139 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:55:47,140 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:55:47,140 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:55:47,646 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:48,220 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:48,220 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:55:48,220 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:55:48,723 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:49,285 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:49,285 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:55:49,285 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:55:49,790 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:50,360 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:50,360 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:55:50,360 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:55:50,860 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:51,417 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:51,417 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:55:51,417 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:55:51,916 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:52,496 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:52,496 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:55:52,496 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:55:52,999 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:53,571 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:53,571 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:55:53,571 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:55:54,075 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:54,648 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:54,648 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:55:54,648 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:55:55,174 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:55,855 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:55,855 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:55:55,855 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:55:56,354 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:56,933 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:56,934 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:55:56,934 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:55:57,428 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:55:57,995 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:55:57,995 - __main__ - INFO - Perturbation complete
2025-12-17 21:55:58,023 - __main__ - INFO - Saved outputs for baseline to outputs/outputs/baseline
2025-12-17 21:55:58,032 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:55:58,033 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 21:55:58,033 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 21:55:58,034 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:02,549 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:02,549 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 21:56:02,549 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 21:56:02,550 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 21:56:03,054 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:05,432 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:05,432 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 21:56:05,432 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 21:56:05,929 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:08,332 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:08,332 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 21:56:08,332 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 21:56:08,859 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:11,299 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:11,299 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 21:56:11,299 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 21:56:11,807 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:14,612 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:14,613 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 21:56:14,613 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 21:56:15,120 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:17,494 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:17,494 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 21:56:17,494 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 21:56:18,006 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:20,376 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:20,376 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 21:56:20,376 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 21:56:20,880 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:23,260 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:23,260 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 21:56:23,260 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 21:56:23,764 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:26,136 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:26,136 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 21:56:26,136 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 21:56:26,654 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:29,488 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:29,488 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 21:56:29,488 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 21:56:29,997 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:32,400 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 21:56:32,400 - __main__ - INFO - Perturbation complete
2025-12-17 21:56:32,428 - __main__ - INFO - Saved outputs for distributed to outputs/outputs/distributed
2025-12-17 21:56:32,453 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:56:32,454 - __main__ - INFO - Running with BATCHING optimization...
2025-12-17 21:56:32,454 - __main__ - INFO - Using batch size: 64 (original: 32)
2025-12-17 21:56:32,456 - __main__ - ERROR - batching failed: Key 'forward_batch_size' is not in struct
    full_key: model.forward_batch_size
    object_type=dict
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1123, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 619, in run_with_batching
    self.cfg.model.forward_batch_size = optimized_batch_size
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 337, in __setattr__
    raise e
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 334, in __setattr__
    self.__set_impl(key, value)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 318, in __set_impl
    self._set_item_impl(key, value)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/basecontainer.py", line 549, in _set_item_impl
    self._validate_set(key, value)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 180, in _validate_set
    target = self._get_node(key) if key is not None else self
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 475, in _get_node
    self._validate_get(key)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 164, in _validate_get
    self._format_and_raise(
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/base.py", line 231, in _format_and_raise
    format_and_raise(
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py", line 899, in format_and_raise
    _raise(ex, cause)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py", line 797, in _raise
    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
omegaconf.errors.ConfigAttributeError: Key 'forward_batch_size' is not in struct
    full_key: model.forward_batch_size
    object_type=dict
2025-12-17 21:56:32,456 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:56:32,457 - __main__ - INFO - Running with QUANTIZATION optimization...
2025-12-17 21:56:32,457 - __main__ - INFO - Applying dynamic int8 quantization...
2025-12-17 21:56:32,748 - __main__ - INFO - Extracting embeddings...
2025-12-17 21:56:32,790 - __main__ - ERROR - quantization failed: Caught NotImplementedError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 97, in _worker
    output = module(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1144, in forward
    encoder_outputs = self.encoder(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 695, in forward
    layer_outputs = layer_module(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 585, in forward
    self_attention_outputs = self.attention(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 515, in forward
    self_outputs = self.self(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 395, in forward
    query_layer = self.transpose_for_scores(self.query(hidden_states))
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 57, in forward
    Y = torch.ops.quantized.linear_dynamic(
  File "/opt/conda/lib/python3.10/site-packages/torch/_ops.py", line 1158, in __call__
    return self._op(*args, **(kwargs or {}))
NotImplementedError: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].

CPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:1027 [kernel]
Meta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]
BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]
Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]
Named: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]
Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]
AutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]
AutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]
AutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]
AutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]
AutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]
AutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]
AutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]
AutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]
AutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]
AutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]
Tracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]
AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]
AutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:466 [backend fallback]
AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:504 [backend fallback]
AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]
AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]
FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]
BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]
FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]
Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]
VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:208 [backend fallback]
PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]
PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]
PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]

Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1123, in run
    perf_metrics, outputs = runner(model, data, adata, genes)
  File "/root/capsule/code/helical-challenge/main.py", line 702, in run_with_quantization
    embeddings = self.extract_embeddings(model, data)
  File "/root/capsule/code/helical-challenge/main.py", line 496, in extract_embeddings
    embeddings = model.get_embeddings(data)
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 193, in get_embs
    outputs = model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 194, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 213, in parallel_apply
    return parallel_apply(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 127, in parallel_apply
    output.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 750, in reraise
    raise exception
NotImplementedError: Caught NotImplementedError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 97, in _worker
    output = module(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1144, in forward
    encoder_outputs = self.encoder(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 695, in forward
    layer_outputs = layer_module(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 585, in forward
    self_attention_outputs = self.attention(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 515, in forward
    self_outputs = self.self(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 395, in forward
    query_layer = self.transpose_for_scores(self.query(hidden_states))
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 57, in forward
    Y = torch.ops.quantized.linear_dynamic(
  File "/opt/conda/lib/python3.10/site-packages/torch/_ops.py", line 1158, in __call__
    return self._op(*args, **(kwargs or {}))
NotImplementedError: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].

CPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:1027 [kernel]
Meta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]
BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]
Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]
Named: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]
Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]
AutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]
AutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]
AutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]
AutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]
AutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]
AutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]
AutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]
AutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]
AutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]
AutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]
Tracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]
AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]
AutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:466 [backend fallback]
AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:504 [backend fallback]
AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]
AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]
FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]
BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]
FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]
Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]
VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:208 [backend fallback]
PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]
PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]
PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]


2025-12-17 21:56:32,791 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:56:32,791 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 21:56:32,791 - __main__ - INFO - ====================================================================================================
2025-12-17 21:56:32,792 - __main__ - INFO - Comparing baseline vs distributed
2025-12-17 21:56:32,942 - __main__ - INFO - Performance metrics saved to: outputs/performance_metrics_20251217_215632.csv
2025-12-17 21:56:32,943 - __main__ - INFO - Comparison metrics saved to: outputs/comparison_metrics_20251217_215632.csv
2025-12-17 21:56:32,946 - __main__ - INFO - Per-gene comparison saved to: outputs/gene_comparison_baseline_vs_distributed.csv
2025-12-17 21:56:32,946 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:56:32,946 - __main__ - INFO - PERFORMANCE SUMMARY
2025-12-17 21:56:32,946 - __main__ - INFO - ====================================================================================================
2025-12-17 21:56:32,949 - __main__ - INFO - 
        method  runtime_seconds  cpu_percent    memory_mb  gpu_memory_mb  gpu_utilization  throughput_cells_per_sec  num_cells  num_genes_perturbed                   timestamp extra_optimization  extra_num_gpus extra_backend
0     baseline        12.716700         74.9  2195.425781     153.536621               41                 78.636754       1000                   10  2025-12-17T21:55:57.996672               none             NaN           NaN
1  distributed        34.366785        153.1  3123.324219     162.161621               50                 29.097863       1000                   10  2025-12-17T21:56:32.401403                NaN             4.0          nccl

2025-12-17 21:56:32,950 - __main__ - INFO - 
SPEEDUP RELATIVE TO BASELINE:
2025-12-17 21:56:32,950 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:56:32,950 - __main__ - INFO - distributed         : 0.37x
2025-12-17 21:56:32,950 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:56:32,950 - __main__ - INFO - OUTPUT COMPARISON SUMMARY
2025-12-17 21:56:32,950 - __main__ - INFO - ====================================================================================================
2025-12-17 21:56:32,953 - __main__ - INFO - 
   method_a     method_b  embedding_pearson  embedding_spearman  embedding_cosine_similarity  embedding_mse  embedding_max_abs_diff  mean_perturbation_correlation  min_perturbation_correlation  max_perturbation_correlation                   timestamp
0  baseline  distributed           0.999998            0.999998                     0.999999   7.678967e-07                0.043351                       0.999997                      0.999993                      0.999999  2025-12-17T21:56:32.940298

2025-12-17 21:56:32,953 - __main__ - INFO - 
OUTPUT QUALITY ASSESSMENT:
2025-12-17 21:56:32,953 - __main__ - INFO - --------------------------------------------------
2025-12-17 21:56:32,953 - __main__ - INFO - ====================================================================================================
2025-12-17 21:56:32,953 - __main__ - INFO - 
All outputs saved to: outputs
2025-12-17 21:56:32,953 - __main__ - INFO - 
====================================================================================================
2025-12-17 21:56:32,953 - __main__ - INFO - PIPELINE COMPLETE!
2025-12-17 21:56:32,953 - __main__ - INFO - ====================================================================================================
2025-12-17 22:08:31,963 - __main__ - INFO - ====================================================================================================
2025-12-17 22:08:31,963 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 22:08:31,963 - __main__ - INFO - ====================================================================================================
2025-12-17 22:08:31,963 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 22:08:31,969 - __main__ - INFO - 
Configuration:
seed: 42
model:
  name: gf-12L-38M-i4096
  batch_size: 128
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  - batching
  - quantization
  batching:
    enabled: true
    batch_size_multiplier: 2
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: true
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: true
  cudnn_benchmark: true
  empty_cache_between_methods: true
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
advanced:
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 22:08:31,969 - __main__ - INFO - Loading Geneformer model...
2025-12-17 22:08:34,049 - __main__ - INFO - Enabling automatic mixed precision
2025-12-17 22:08:34,050 - __main__ - ERROR - Pipeline failed with error: 'GeneformerPerturbationPipeline' object has no attribute 'check_'
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1211, in main
    pipeline.run()
  File "/root/capsule/code/helical-challenge/main.py", line 1058, in run
    model = self.load_model()
  File "/root/capsule/code/helical-challenge/main.py", line 390, in load_model
    if self.check_:
AttributeError: 'GeneformerPerturbationPipeline' object has no attribute 'check_'
2025-12-17 22:09:38,937 - __main__ - INFO - ====================================================================================================
2025-12-17 22:09:38,937 - __main__ - INFO - GENEFORMER PERTURBATION PIPELINE
2025-12-17 22:09:38,937 - __main__ - INFO - ====================================================================================================
2025-12-17 22:09:38,937 - __main__ - INFO - Experiment: geneformer_perturbation
2025-12-17 22:09:38,942 - __main__ - INFO - 
Configuration:
seed: 42
model:
  name: gf-12L-38M-i4096
  batch_size: 128
  max_length: 2048
  device: cuda:0
data:
  pertpy_data_identifier: norman_2019
  condition_filter: control
  gene_names_column: index
  use_raw_counts: false
  preprocess: true
  normalize: true
  filter_genes: true
  min_genes: 200
  min_cells: 3
  max_cells: 1000
  max_genes: 100
perturbation:
  gene_list: null
  num_genes: 10
  perturbation_type: knockout
  selection_method: top_expressed
  perturbation_strength: 2.0
optimization:
  methods:
  - distributed
  - batching
  - quantization
  batching:
    enabled: true
    batch_size_multiplier: 2
  quantization:
    enabled: true
    dtype: qint8
    quantize_layers:
    - torch.nn.Linear
    dynamic: true
  onnx:
    enabled: true
    opset_version: 14
    optimize: true
    use_gpu: true
    precision: FP16
  distributed:
    enabled: true
    backend: nccl
    world_size: null
    use_data_parallel: true
output:
  dir: outputs
  save_outputs: true
  compression: true
  precision: float32
  save_embeddings: true
  save_perturbations: true
  save_metadata: true
  save_cell_ids: true
  save_gene_names: true
  save_detailed_comparisons: true
  log_level: INFO
  log_to_file: true
  log_file: pipeline.log
hardware:
  device: auto
  mixed_precision: true
  cudnn_benchmark: true
  empty_cache_between_methods: true
experiment:
  name: geneformer_perturbation
  tags: []
  notes: ''
reproducibility:
  deterministic: true
advanced:
  compile_model: false
  compile_backend: inductor
  continue_on_error: true
validation:
  min_correlation: 0.95
  max_mse: 0.01
  warn_on_threshold: true
  check_nan: true
  check_inf: true

2025-12-17 22:09:38,943 - __main__ - INFO - Loading Geneformer model...
2025-12-17 22:09:41,016 - __main__ - INFO - Enabling automatic mixed precision
2025-12-17 22:09:41,016 - __main__ - INFO - Model loaded: gf-12L-38M-i4096
2025-12-17 22:09:41,017 - __main__ - INFO - Loading data: norman_2019
2025-12-17 22:10:06,394 - __main__ - INFO - Loaded 11835 cells, 19018 genes
2025-12-17 22:10:06,394 - __main__ - INFO - Preprocessing data...
2025-12-17 22:10:08,823 - __main__ - INFO - After filtering: 11835 cells, 18215 genes
2025-12-17 22:10:08,985 - __main__ - INFO - Data normalized
2025-12-17 22:10:08,991 - __main__ - INFO - Subsetted to 1000 cells for testing
2025-12-17 22:10:08,993 - __main__ - INFO - Subsetted to 100 genes for testing
2025-12-17 22:10:08,993 - __main__ - INFO - Tokenizing data...
2025-12-17 22:10:09,900 - __main__ - INFO - Tokenization complete
2025-12-17 22:10:09,900 - __main__ - INFO - Selected 10 genes using method: top_expressed
2025-12-17 22:10:09,901 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:09,901 - __main__ - INFO - Running BASELINE (no optimization)...
2025-12-17 22:10:09,903 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:11,121 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:11,121 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 22:10:11,121 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 22:10:11,121 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 22:10:11,626 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:12,024 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:12,024 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 22:10:12,024 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 22:10:12,525 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:12,887 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:12,887 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 22:10:12,887 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 22:10:13,393 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:13,752 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:13,752 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 22:10:13,752 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 22:10:14,258 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:14,617 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:14,617 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 22:10:14,617 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 22:10:15,139 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:15,501 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:15,501 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 22:10:15,501 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 22:10:16,006 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:16,365 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:16,365 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 22:10:16,365 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 22:10:16,865 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:17,226 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:17,226 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 22:10:17,226 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 22:10:17,728 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:18,086 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:18,086 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 22:10:18,086 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 22:10:18,596 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:18,953 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:18,953 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 22:10:18,953 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 22:10:19,449 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:19,806 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:19,806 - __main__ - INFO - Perturbation complete
2025-12-17 22:10:20,853 - __main__ - INFO - Saved outputs for baseline to outputs/outputs/baseline
2025-12-17 22:10:21,020 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:21,021 - __main__ - INFO - Running with DISTRIBUTED optimization...
2025-12-17 22:10:21,021 - __main__ - INFO - Using 4 GPUs with DataParallel
2025-12-17 22:10:21,022 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:23,992 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:23,992 - __main__ - INFO - Performing perturbation on 10 genes...
2025-12-17 22:10:23,992 - __main__ - INFO - Perturbing gene: UBE2J2 (type: knockout)
2025-12-17 22:10:23,992 - __main__ - WARNING - Using manual perturbation for UBE2J2
2025-12-17 22:10:24,502 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:25,481 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:25,481 - __main__ - INFO - Perturbing gene: SDF4 (type: knockout)
2025-12-17 22:10:25,481 - __main__ - WARNING - Using manual perturbation for SDF4
2025-12-17 22:10:25,990 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:26,943 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:26,943 - __main__ - INFO - Perturbing gene: RER1 (type: knockout)
2025-12-17 22:10:26,943 - __main__ - WARNING - Using manual perturbation for RER1
2025-12-17 22:10:27,455 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:28,406 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:28,406 - __main__ - INFO - Perturbing gene: NOC2L (type: knockout)
2025-12-17 22:10:28,406 - __main__ - WARNING - Using manual perturbation for NOC2L
2025-12-17 22:10:28,910 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:29,862 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:29,862 - __main__ - INFO - Perturbing gene: GNB1 (type: knockout)
2025-12-17 22:10:29,862 - __main__ - WARNING - Using manual perturbation for GNB1
2025-12-17 22:10:30,377 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:31,333 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:31,333 - __main__ - INFO - Perturbing gene: FAAP20 (type: knockout)
2025-12-17 22:10:31,333 - __main__ - WARNING - Using manual perturbation for FAAP20
2025-12-17 22:10:31,844 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:32,792 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:32,792 - __main__ - INFO - Perturbing gene: SSU72 (type: knockout)
2025-12-17 22:10:32,792 - __main__ - WARNING - Using manual perturbation for SSU72
2025-12-17 22:10:33,308 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:34,253 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:34,253 - __main__ - INFO - Perturbing gene: MRPL20 (type: knockout)
2025-12-17 22:10:34,254 - __main__ - WARNING - Using manual perturbation for MRPL20
2025-12-17 22:10:34,758 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:35,706 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:35,706 - __main__ - INFO - Perturbing gene: AURKAIP1 (type: knockout)
2025-12-17 22:10:35,706 - __main__ - WARNING - Using manual perturbation for AURKAIP1
2025-12-17 22:10:36,207 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:37,159 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:37,159 - __main__ - INFO - Perturbing gene: RPL22 (type: knockout)
2025-12-17 22:10:37,159 - __main__ - WARNING - Using manual perturbation for RPL22
2025-12-17 22:10:37,677 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:38,633 - __main__ - INFO - Extracted embeddings shape: (1000, 512)
2025-12-17 22:10:38,633 - __main__ - INFO - Perturbation complete
2025-12-17 22:10:39,724 - __main__ - INFO - Saved outputs for distributed to outputs/outputs/distributed
2025-12-17 22:10:39,770 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:39,770 - __main__ - INFO - Running with BATCHING optimization...
2025-12-17 22:10:39,770 - __main__ - INFO - Using batch size: 256 (original: 128)
2025-12-17 22:10:39,772 - __main__ - ERROR - batching failed: Key 'forward_batch_size' is not in struct
    full_key: model.forward_batch_size
    object_type=dict
Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1123, in run
    if self.validate_outputs(outputs):
  File "/root/capsule/code/helical-challenge/main.py", line 619, in run_with_batching
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 337, in __setattr__
    raise e
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 334, in __setattr__
    self.__set_impl(key, value)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 318, in __set_impl
    self._set_item_impl(key, value)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/basecontainer.py", line 549, in _set_item_impl
    self._validate_set(key, value)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 180, in _validate_set
    target = self._get_node(key) if key is not None else self
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 475, in _get_node
    self._validate_get(key)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py", line 164, in _validate_get
    self._format_and_raise(
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/base.py", line 231, in _format_and_raise
    format_and_raise(
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py", line 899, in format_and_raise
    _raise(ex, cause)
  File "/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py", line 797, in _raise
    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
omegaconf.errors.ConfigAttributeError: Key 'forward_batch_size' is not in struct
    full_key: model.forward_batch_size
    object_type=dict
2025-12-17 22:10:39,773 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:39,773 - __main__ - INFO - Running with QUANTIZATION optimization...
2025-12-17 22:10:39,774 - __main__ - INFO - Applying dynamic int8 quantization...
2025-12-17 22:10:40,065 - __main__ - INFO - Extracting embeddings...
2025-12-17 22:10:40,214 - __main__ - ERROR - quantization failed: Caught NotImplementedError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 97, in _worker
    output = module(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1144, in forward
    encoder_outputs = self.encoder(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 695, in forward
    layer_outputs = layer_module(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 585, in forward
    self_attention_outputs = self.attention(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 515, in forward
    self_outputs = self.self(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 395, in forward
    query_layer = self.transpose_for_scores(self.query(hidden_states))
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 57, in forward
    Y = torch.ops.quantized.linear_dynamic(
  File "/opt/conda/lib/python3.10/site-packages/torch/_ops.py", line 1158, in __call__
    return self._op(*args, **(kwargs or {}))
NotImplementedError: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].

CPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:1027 [kernel]
Meta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]
BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]
Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]
Named: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]
Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]
AutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]
AutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]
AutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]
AutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]
AutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]
AutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]
AutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]
AutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]
AutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]
AutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]
Tracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]
AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]
AutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:466 [backend fallback]
AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:504 [backend fallback]
AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]
AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]
FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]
BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]
FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]
Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]
VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:208 [backend fallback]
PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]
PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]
PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]

Traceback (most recent call last):
  File "/root/capsule/code/helical-challenge/main.py", line 1123, in run
    if self.validate_outputs(outputs):
  File "/root/capsule/code/helical-challenge/main.py", line 702, in run_with_quantization
  File "/root/capsule/code/helical-challenge/main.py", line 496, in extract_embeddings
    self,
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/model.py", line 238, in get_embeddings
    embeddings = get_embs(
  File "/opt/conda/lib/python3.10/site-packages/helical/models/geneformer/geneformer_utils.py", line 193, in get_embs
    outputs = model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 194, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 213, in parallel_apply
    return parallel_apply(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 127, in parallel_apply
    output.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 750, in reraise
    raise exception
NotImplementedError: Caught NotImplementedError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 97, in _worker
    output = module(*input, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1463, in forward
    outputs = self.bert(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1144, in forward
    encoder_outputs = self.encoder(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 695, in forward
    layer_outputs = layer_module(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 585, in forward
    self_attention_outputs = self.attention(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 515, in forward
    self_outputs = self.self(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 395, in forward
    query_layer = self.transpose_for_scores(self.query(hidden_states))
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/dynamic/modules/linear.py", line 57, in forward
    Y = torch.ops.quantized.linear_dynamic(
  File "/opt/conda/lib/python3.10/site-packages/torch/_ops.py", line 1158, in __call__
    return self._op(*args, **(kwargs or {}))
NotImplementedError: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].

CPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:1027 [kernel]
Meta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]
BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]
Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]
Named: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]
Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]
AutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]
AutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]
AutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]
AutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]
AutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]
AutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]
AutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]
AutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]
AutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]
AutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]
Tracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]
AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]
AutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:466 [backend fallback]
AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:504 [backend fallback]
AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]
AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]
FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]
BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]
FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]
Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]
VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:208 [backend fallback]
PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]
PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]
PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]


2025-12-17 22:10:40,215 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:40,216 - __main__ - INFO - COMPARING OUTPUTS TO BASELINE
2025-12-17 22:10:40,216 - __main__ - INFO - ====================================================================================================
2025-12-17 22:10:40,216 - __main__ - INFO - Comparing baseline vs distributed
2025-12-17 22:10:40,380 - __main__ - INFO - Performance metrics saved to: outputs/performance_metrics_20251217_221040.csv
2025-12-17 22:10:40,381 - __main__ - INFO - Comparison metrics saved to: outputs/comparison_metrics_20251217_221040.csv
2025-12-17 22:10:40,384 - __main__ - INFO - Per-gene comparison saved to: outputs/gene_comparison_baseline_vs_distributed.csv
2025-12-17 22:10:40,384 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:40,384 - __main__ - INFO - PERFORMANCE SUMMARY
2025-12-17 22:10:40,384 - __main__ - INFO - ====================================================================================================
2025-12-17 22:10:40,388 - __main__ - INFO - 
        method  runtime_seconds  cpu_percent    memory_mb  gpu_memory_mb  gpu_utilization  throughput_cells_per_sec  num_cells  num_genes_perturbed                   timestamp extra_optimization  extra_num_gpus extra_backend
0     baseline         9.905391         72.8  2170.449219     153.536621               45                100.955131       1000                   10  2025-12-17T22:10:19.809803               none             NaN           NaN
1  distributed        17.612777        126.5  3070.695312     161.661621               54                 56.776964       1000                   10  2025-12-17T22:10:38.688592                NaN             4.0          nccl

2025-12-17 22:10:40,388 - __main__ - INFO - 
SPEEDUP RELATIVE TO BASELINE:
2025-12-17 22:10:40,388 - __main__ - INFO - --------------------------------------------------
2025-12-17 22:10:40,389 - __main__ - INFO - distributed         : 0.56x
2025-12-17 22:10:40,389 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:40,389 - __main__ - INFO - OUTPUT COMPARISON SUMMARY
2025-12-17 22:10:40,389 - __main__ - INFO - ====================================================================================================
2025-12-17 22:10:40,392 - __main__ - INFO - 
   method_a     method_b  embedding_pearson  embedding_spearman  embedding_cosine_similarity  embedding_mse  embedding_max_abs_diff  mean_perturbation_correlation  min_perturbation_correlation  max_perturbation_correlation                   timestamp
0  baseline  distributed           0.999999                 1.0                          1.0   1.819798e-07                0.027906                       0.999999                      0.999999                           1.0  2025-12-17T22:10:40.378292

2025-12-17 22:10:40,392 - __main__ - INFO - 
OUTPUT QUALITY ASSESSMENT:
2025-12-17 22:10:40,392 - __main__ - INFO - --------------------------------------------------
2025-12-17 22:10:40,392 - __main__ - INFO - ====================================================================================================
2025-12-17 22:10:40,392 - __main__ - INFO - 
All outputs saved to: outputs
2025-12-17 22:10:40,393 - __main__ - INFO - 
====================================================================================================
2025-12-17 22:10:40,393 - __main__ - INFO - PIPELINE COMPLETE!
2025-12-17 22:10:40,393 - __main__ - INFO - ====================================================================================================
