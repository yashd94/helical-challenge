# Helical challenge

> [!IMPORTANT]  
> * Quantization uses nvidia-modelopt to auto-quantize, so each layer is optimized to a different precision 
> * ONNX inference is set up using torch-ort but is not currently tested

> [!NOTE]  
> Improvements:
> 1. Device-specific GPU memory calculation for the distributed optimization
> 2. Perform perturbations on the tokenized dataset 
> 3. Ensure that normalization is not repeated (raw counts passed to Geneformer tokenizer)
> 4. Grid comparator (e.g. heatmap) for optimization methods
> 5. Fix different quantization settings (qint8 results in loss of information; fp8 not working)
> 6. Fix ONNX inference using torch_ort (CUDA version mismatch)

## Usage

```python
time python3 main.py
```

## Outputs

See `outputs/`. Compares post-perturbation embeddings generated by each optimization method using Pearson's correlation and MSE. Compares performance based on CPU & GPU utilization. See below for an example.

```bash
[2025-12-23 17:02:51,245][__main__][INFO] - batching            : 1.35x
[2025-12-23 17:02:51,246][__main__][INFO] - quantization        : 0.99x
[2025-12-23 17:02:51,246][__main__][INFO] - distributed_ddp     : 1.36x
```

| method          | runtime_seconds    | cpu_percent | memory_mb     | gpu_memory_mb  | gpu_utilization | throughput_cells_per_sec | num_cells | num_genes_perturbed | timestamp                  | extra_optimization | extra_batch_size | extra_original_batch_size | extra_multiplier | extra_quantization_dtype | extra_num_gpus | extra_backend | extra_distribution_method |
| --------------- | ------------------ | ----------- | ------------- | -------------- | --------------- | ------------------------ | --------- | ------------------- | -------------------------- | ------------------ | ---------------- | ------------------------- | ---------------- | ------------------------ | -------------- | ------------- | ------------------------- |
| baseline        | 162.55185556411743 | 100.0       | 1120.00390625 | 9.125          | 38              | 61.51883019296307        | 10000     | 20                  | 2025-12-23T16:55:16.849047 | none               |                  |                           |                  |                          |                |               |                           |
| batching        | 119.97875213623047 | 100.0       | 6249.82421875 | 48.40478515625 | 47              | 83.34809140743063        | 10000     | 20                  | 2025-12-23T16:57:26.973792 |                    | 32.0             | 16.0                      | 2.0              |                          |                |               |                           |
| quantization    | 163.52998852729797 | 100.0       | 6455.0078125  | 48.40478515625 | 38              | 61.15086345970547        | 10000     | 20                  | 2025-12-23T17:00:20.375258 |                    |                  |                           |                  | fp4                      |                |               |                           |
| distributed_ddp | 119.80421471595764 | 2.6         | 6941.41796875 | 9.125          | 0               | 83.46951752664862        | 10000     | 20                  | 2025-12-23T17:02:37.923913 |                    |                  |                           |                  |                          | 4.0            | nccl          | DDP                       |

## Configuration 

Controlled by `conf/config.yaml`. See below for an example.

```yaml
# ============================================================================
# REPRODUCIBILITY
# ============================================================================
reproducibility:
  deterministic: true               # Set seed
  seed: 42
  
# ============================================================================
# MODEL CONFIGS
# ============================================================================
model:
  name: "gf-6L-10M-i2048" # Model identifier
         # "gf-12L-38M-i4096"  
         # "gf-12L-38M-i4096",
         # "gf-12L-38M-i4096-CLcancer",
         # "gf-12L-40M-i2048",
         # "gf-12L-40M-i2048-CZI-CellxGene",
         # "gf-12L-104M-i4096",
         # "gf-12L-104M-i4096-CLcancer",
         # "gf-20L-151M-i4096",
         # "gf-18L-316M-i4096",
  batch_size: 16          # Base batch size for inference
  device: 'cuda:0'


# ============================================================================
# DATA CONFIGS
# ============================================================================
data:
  pertpy_data_identifier: "norman_2019"
  condition_filter: "control"
  save_tokenized_data: true
  
  # Preprocessing options
  gene_names_column: "index"
  use_raw_counts: false
  preprocess: true
  normalize: false
  filter_genes: true
  min_genes: 100      # Minimum genes per cell
  min_cells: 3        # Minimum cells per gene
  
  # Subset data for testing
  max_cells: 10000  # Limit number of cells for faster testing
  max_genes: 500   # Limit number of genes

# ============================================================================
# PERTURBATION CONFIGS
# ============================================================================
perturbation:
  # Option 1: Explicit gene list (set num_genes to null if using this)
  gene_list: null
  # gene_list: ["BRCA1", "TP53", "MYC", "EGFR", "KRAS"]
  
  # Option 2: Number of top variable genes (set gene_list to null if using this)
  num_genes: 20
  
  # Perturbation settings
  perturbation_type: "knockout"  # Options: knockout, overexpression
  
  # Gene selection method when using num_genes
  selection_method: "top_expressed"  # Options: highly_variable, top_expressed, random
  
  # Additional perturbation options
  perturbation_strength: 2.0  # For overexpression experiments
  
  # Save perturbed data to cache directory
  save_perturbed_data: true
# ============================================================================
# OPTIMIZATION CONFIGS
# ============================================================================
optimization:
  # Methods to run: batching, quantization, onnx, distributed, all
  methods:
    - all
  
  # Batching optimization
  batching:
    enabled: true
    batch_size_multiplier: 2  # Multiply base batch_size by this factor

  # Quantization optimization
  quantization:
    enabled: true
    dtype: "fp4"           # Options: qint8, float16, fp8, fp4
    calibration_data_size: 32
  
  # ONNX optimization
  onnx:
    enabled: true
    use_gpu: true           # Use ONNX GPU runtime if available
    precision: "FP16"
  
  # Distributed optimization
  distributed:
    enabled: true
    backend: "nccl"         # Options: nccl, gloo

# ============================================================================
# OUTPUT CONFIGS
# ============================================================================
output:
  dir: "outputs"                    # Base output directory
  cache_dir: "/scratch"             # Cache directory
  save_outputs: true                # Save model outputs (embeddings and perturbations)
  
  # Output format options
  compression: true                 # Options: null, "gzip", "lzf"
  precision: "float32"              # Options: float32, float16
  
  # Comparison outputs
  save_detailed_comparisons: true   # Save per-gene comparison CSVs
  
  # Logging
  log_level: "INFO"                 # Options: DEBUG, INFO, WARNING, ERROR
  log_to_file: true
  log_file: "pipeline.log"

# ============================================================================
# HARDWARE CONFIGS
# ============================================================================
hardware:
  device: "auto"                    # Options: auto, cuda, cpu, cuda:0, cuda:1, etc.
  mixed_precision: false            # Use automatic mixed precision (AMP)
  cudnn_benchmark: true             # Enable cuDNN benchmarking
  
  # Memory management
  empty_cache_between_methods: true # Clear GPU cache between optimization methods

# ============================================================================
# EXPERIMENT TRACKING
# ============================================================================
experiment:
  name: "geneformer_perturbation_example"
  tags: []
  notes: ""

# ============================================================================
# ADVANCED OPTIONS
# ============================================================================
advanced:
  # Compilation (PyTorch 2.0+)
  compile_model: false
  compile_backend: "inductor"       # Options: inductor, aot_eager, cudagraphs
  
  # Error handling
  continue_on_error: true           # Continue if one optimization method fails

# ============================================================================
# VALIDATION
# ============================================================================
validation:
  # Thresholds for output comparison
  min_correlation: 0.95             # Minimum correlation with baseline
  max_mse: 0.01                     # Maximum MSE with baseline
  warn_on_threshold: true           # Warn if thresholds are exceeded
  
  # Sanity checks
  check_nan: true                   # Check for NaN values in outputs
  check_inf: true                   # Check for Inf values in outputs
```